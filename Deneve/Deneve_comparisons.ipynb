{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Comparing different papers of Sophie Deneve"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Boerlin et al 2013"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Assume an external dynamical system $\\dot{\\mathbf{x}}(t)=\\mathbf{A}\\mathbf{x}(t)+\\mathbf{c}(t)$. An output readout layer rate codes the $J$ dynamical variables $\\mathbf{x}(t)$ as $\\dot{\\mathbf{\\hat{x}}}=-\\lambda_d \\mathbf{\\hat{x}} + \\mathbf{\\Gamma} \\mathbf{o}(t)$. The recurrent network weights are derived from the readout weights $\\mathbf{\\Gamma}$, the desired dynamics $\\mathbf{A}$ and the penalty scalar $\\mu$ as\n",
      "\n",
      "$\\mathbf{W}=\\mathbf{\\Omega}^s h_d^1(u) - \\mathbf{\\Omega}^f \\delta(u)$ ...Eqn(40).\n",
      "\n",
      "The recurrent network neurons receive the same input $\\mathbf{c}(t)$ as the dynamical system, and spike only 'as much as is necessary' for the readout to track the dynamical variables $\\mathbf{x}(t)$.\n",
      "\n",
      "$\\dot{\\mathbf{V}}(t) = -\\lambda_V\\mathbf{V}(t) + \\frac{1}{\\lambda_d}\\mathbf{\\Omega}^s\\mathbf{r}(t) - \\mathbf{\\Omega}^f\\mathbf{o}(t) + \\mathbf{\\Gamma}^T\\mathbf{c}(t)$ ...Eqn(37)\n",
      "\n",
      "$\\mathbf{\\Omega}^s = \\mathbf{\\Gamma}^T(\\mathbf{A}+\\lambda_d\\mathbf{I})\\mathbf{\\Gamma}$ ...Eqn(38)\n",
      "\n",
      "$\\mathbf{\\Omega}^f = \\left(\\mathbf{\\Gamma}^T\\mathbf{\\Gamma}+\\mu\\lambda_d^2\\right)$ ...Eqn(39)\n",
      "\n",
      "Cost function:\n",
      "\n",
      "$E(t) = \\int_0^t du \\left(|| \\mathbf{x}(u)-\\mathbf{\\hat{x}}(u)||_2^2 +\\nu ||\\mathbf{r}(u)||_1 +\\mu ||\\mathbf{r}(u)||_2^2 \\right)~~$     ...Eqn(4)\n",
      "\n",
      "Noise model:\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Bourdukan et al 2012"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cost function:\n",
      "\n",
      "As above, but $\\nu=0$ and $\\mu=0$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Boerlin and Deneve 2011, Spike based population coding and working memory"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Assume stimulus evolves as as drift-diffusion process $dx_t=\\delta dt+ \\sigma dW_t$, where $W$ is a Wiener process."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Each output neuron codes for the log posterior $L_i(t)\\equiv l(x_t,t)|_{x_t=x_i}$ of its preferred value $x_i$ in the discretized stimulus space $(x_1,x_2,...,x_N$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Response likelihood is assumed to belong to an exponential family with sufficient linear statistics:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$p(\\mathbf{S}^n_{t}|x_t)=\\Phi^n(\\mathbf{S}^n_{t})\\Psi^n(x_t)\\exp\\left(\\sum_j H^n_j(x_t)S^n_{t,j}\\right)$\n",
      "\n",
      "where $\\Phi^n(\\mathbf{S}^n_{t})$ and $\\Psi^n(x_t)$ are arbitrary functions, and\n",
      "\n",
      "$\\mathbf{H}^n(x_t)'=\\Sigma^-1(x_t)\\mathbf{f}^n(x_t)'$, where $\\mathbf{f}^n(x_t)$ are the neurons' tuning curves."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The output neurons approximate $L_i(t)$ by $G_i(t)$, and follow the dynamics:\n",
      "\n",
      "$\\dot{G_i}(t)=-\\lambda G_i +\\sum_{ij}\\Gamma_{ij}O_j(t)$ ...Eqn(20),\n",
      "\n",
      "where $O_j(t)$ is the spike train of the output layer itself."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "put in a figure"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dynamics of $L_i(t)$ are calculated assuming an ideal observer and assuming responses of input neurons are independent of each other and depend only on current stimulus location [But the input may be an integral of locations, There is often delayed lateral inhibition too. The input is a filtered version of the stimulus over all time!] as Eqn (19)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An approximation of the dynamics assuming $L_i(t)\\approx G_i(t)$ is:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$\\dot{L_i}(t)=-\\lambda L_i(t)+Y_i(t)+Z_i^2(t)+I_i(t)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "where I_i(t) is the input current to neuron $i$ at time $t$ [where did this come from? output layer has synaptic input already.]. $Y_i(t)$ and $Z_i(t)$ defined below."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$Y_i(t)\\equiv \\lambda G_i(t) -\\delta \\partial_x G_i(t) +\\frac{\\sigma^2}{2} \\partial_xx G_i(t)$\n",
      "\n",
      "$Z_i(t) \\equiv $\n",
      "\n",
      "Using Eqn(20), we can get the dynamical equations for $Y_i(t)$ and $Z_i(t)$ involving the stimulus dynamics constants and the output weights $\\Gamma_{ij}$ and their spatial derivatives."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cost function is $\\sum_j(L_j(t)-G_j(t))^2$. Only those output neurons fire whose spike causes a kernel that brings $\\mathbf{L}$ closer to $\\mathbf{G}$.\n",
      "\n",
      "This results in the firing condition:\n",
      "\n",
      "$\\sum_j \\Gamma_{ji} (L_j(t)-G_j(t)) > \\sum_j \\Gamma_{ji}^2/2$\n",
      "\n",
      "where the LHS can be construed as the membrane potential of an LIF neuron and the RHS as the threshold."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The membrane potential follows the dynamics:\n",
      "\n",
      "$\\dot{V_i}(t) = -\\lambda V_i(t) +\\sum_n\\sum_j\\{[\\mathbf{\\Gamma}^T \\mathbf{H}^n]_ij S^n_j(t)-\\Gamma_ij^T\\log\\Psi^n_i\\}-\\sum_{j\\ne i}[\\mathbf{\\Gamma}^T\\mathbf{\\Gamma}]_{ij}O_j(t)+U_i(\\mathbf{O},t)$\n",
      "\n",
      "where $U_i(\\mathbf{O},t) = Y_i(t)+\\sum_j \\Gamma^T_{ij}Z_j(t)^2$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What the inputs to the LIF neuron? And what are the learned quantities? Where did the current $I_i(t)$ disappear?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}